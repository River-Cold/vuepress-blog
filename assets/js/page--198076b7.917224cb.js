(window.webpackJsonp=window.webpackJsonp||[]).push([[9],{542:function(_,v,e){"use strict";e.r(v);var a=e(1),r=Object(a.a)({},(function(){var _=this,v=_.$createElement,e=_._self._c||v;return e("ContentSlotsDistributor",{attrs:{"slot-key":_.$parent.slotKey}},[e("p",[_._v("作者：Nnnnnnnniii\n链接：https://www.nowcoder.com/discuss/664535?source_id=discuss_experience_nctrack&channel=-1\n来源：牛客网")]),_._v(" "),e("h1",{attrs:{id:"字节大数据研发实习一面二面hr面-已oc"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#字节大数据研发实习一面二面hr面-已oc"}},[_._v("#")]),_._v(" 字节大数据研发实习一面二面hr面（已oc）")]),_._v(" "),e("h2",{attrs:{id:"一面-1h15min-5-19"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#一面-1h15min-5-19"}},[_._v("#")]),_._v(" 一面，1h15min，5.19")]),_._v(" "),e("p",[_._v("1.先来个自我介绍吧")]),_._v(" "),e("p",[_._v("3.kafka掌握怎么样，flink有没有接触过呢")]),_._v(" "),e("p",[_._v("4.先来个mr过程吧")]),_._v(" "),e("blockquote",[e("p",[_._v("MapReduce的工作流程大致可以分为5步：")]),_._v(" "),e("ol",[e("li",[e("p",[_._v("分片、格式化数据")]),_._v(" "),e("p",[_._v("分片操作：将源文件划分为大小相等的小数据块，即数据分片split。")]),_._v(" "),e("p",[_._v("格式化操作：将划分好的分片（split）格式化为键值对<key,value>形式的数据，其中，key代表偏移量，value代表每一行内容。")])]),_._v(" "),e("li",[e("p",[_._v("执行MapTask")]),_._v(" "),e("p",[e("strong",[_._v("写入内存缓冲区")]),_._v("：每个Map任务都有一个内存缓冲区，输入的分片（split）数据经过Map任务处理后的中间结果写入内存缓冲区")]),_._v(" "),e("p",[e("strong",[_._v("写入磁盘")]),_._v("：如果写入的数据达到内存缓冲的阈值，会启动一个线程将内存中的溢出数据写入磁盘，同时不影响Map中间结果继续写入缓冲区。")]),_._v(" "),e("p",[e("strong",[_._v("对key进行排序")]),_._v("：在溢写过程中，MapReduce框架会对key进行排序。")]),_._v(" "),e("p",[e("strong",[_._v("合并溢写文件")]),_._v("：如果中间结果比较大，会形成多个溢写文件，最后的缓冲区数据也会全部溢写入磁盘形成一个溢写文件，如果是多个溢写文件，则最后合并所有的溢写文件为一个文件。输出形式为<key,value>")])]),_._v(" "),e("li",[e("p",[_._v("执行Shuffle过程")]),_._v(" "),e("p",[_._v("将MapTask输出的处理结果数据分发给ReduceTask，并在分发的过程中，对数据按照key进行分区和排序，输出形式为<key,{value,list}>")])]),_._v(" "),e("li",[e("p",[_._v("执行ReduceTask")]),_._v(" "),e("p",[_._v("输入ReduceTask的数据流是<key,{value list}>形式，用户可以自定义reduce()方法进行逻辑处理，最终以<key,value>的形式输出")])]),_._v(" "),e("li",[e("p",[_._v("写入文件")]),_._v(" "),e("p",[_._v("MapReduce框架自动将ReduceTask生成的<key,value>传入OutputFormat的write方法，实现文件写入。")])])])]),_._v(" "),e("p",[_._v("5.每个小文件为什么要进行"),e("a",{attrs:{href:""}},[_._v("排序")]),_._v("，最后合成的大文件为什么进行"),e("a",{attrs:{href:""}},[_._v("排序")])]),_._v(" "),e("p",[_._v("6.一个wordcount案例，具体各个流程，map怎么做，reduce怎么做，很细")]),_._v(" "),e("p",[_._v("7.spark掌握怎么样，我说了解，然后就没问了")]),_._v(" "),e("p",[_._v("8.数仓呢，数据仓库的分层能说一下吗")]),_._v(" "),e("p",[_._v("9.数仓知识还了解什么")]),_._v(" "),e("p",[_._v("10.你刚刚说雪花模型把维度表规范化了，那说一下你了解的范式吧")]),_._v(" "),e("p",[_._v("11.做题吧，两道sql，两道"),e("a",{attrs:{href:""}},[_._v("算法")]),_._v("，写出来")]),_._v(" "),e("p",[_._v("11.1")]),_._v(" "),e("p",[_._v("订单表 orders：订单 ID (order_id)、"),e("a",{attrs:{href:""}},[_._v("销售")]),_._v(" (employee_id)、成交价格 (price)")]),_._v(" "),e("p",[e("a",{attrs:{href:""}},[_._v("销售")]),_._v("表 employees："),e("a",{attrs:{href:""}},[_._v("销售")]),_._v(" ID (employee_id)、"),e("a",{attrs:{href:""}},[_._v("销售")]),_._v("姓名 (employee_name)、所在区域 (region) 求各个"),e("a",{attrs:{href:""}},[_._v("销售")]),_._v("的总"),e("a",{attrs:{href:""}},[_._v("销售")]),_._v("额，要求有"),e("a",{attrs:{href:""}},[_._v("销售")]),_._v(" ID、姓名、所在区域")]),_._v(" "),e("p",[_._v("11.2")]),_._v(" "),e("p",[_._v("订单表 orders：订单 ID (order_id)、"),e("a",{attrs:{href:""}},[_._v("销售")]),_._v(" (employee_id)、成交价格 (price)")]),_._v(" "),e("p",[e("a",{attrs:{href:""}},[_._v("销售")]),_._v("表 employees："),e("a",{attrs:{href:""}},[_._v("销售")]),_._v(" ID (employee_id)、"),e("a",{attrs:{href:""}},[_._v("销售")]),_._v("姓名 (employee_name)、所在区域 (region) 求各个区域"),e("a",{attrs:{href:""}},[_._v("销售")]),_._v("额最高的"),e("a",{attrs:{href:""}},[_._v("销售")]),_._v("对应的"),e("a",{attrs:{href:""}},[_._v("销售")]),_._v(" ID、姓名、所在区域、"),e("a",{attrs:{href:""}},[_._v("销售")]),_._v("额")]),_._v(" "),e("p",[_._v("11.3")]),_._v(" "),e("p",[_._v("给定一个升序整数数列 L（L 中没有重复元素）和一个整数 n，判定 n 是否在 L 中")]),_._v(" "),e("p",[_._v("11.4")]),_._v(" "),e("p",[_._v("给定一个集合，求这个"),e("a",{attrs:{href:""}},[_._v("集合的所有子集")]),_._v("组成的集合。可用序列来表示集合。")]),_._v(" "),e("p",[_._v("12.反问：您觉得我之后需要加强哪方面的学习")]),_._v(" "),e("p",[_._v("总结：面试的很舒服，聊着聊着状态就特别好，题都a了")]),_._v(" "),e("p",[_._v("一面结束，第二天早上就接到电话进行二面，约5.24")]),_._v(" "),e("h2",{attrs:{id:"二面-1h-5-24"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#二面-1h-5-24"}},[_._v("#")]),_._v(" 二面，1h，5.24")]),_._v(" "),e("p",[_._v("二面面试官也很好，都有回应")]),_._v(" "),e("p",[_._v("1.自我介绍")]),_._v(" "),e("p",[_._v("2.实习时长")]),_._v(" "),e("p",[_._v("2.说一下mysql的索引吧")]),_._v(" "),e("p",[_._v("3.B树和B+树的区别，问的很细")]),_._v(" "),e("p",[_._v("4.你是考研还是保研，顺便说了下我简历的问题")]),_._v(" "),e("p",[_._v("5.spark掌握如何？问的很细，具体忘记了，完全没套路，很发散")]),_._v(" "),e("p",[_._v("6.jvm掌握如何？")]),_._v(" "),e("p",[_._v("7.多线程呢？")]),_._v(" "),e("p",[_._v("8.kafka呢，partition为什么采用磁盘顺序写？")]),_._v(" "),e("p",[_._v("9.500G 的文件，机器 1core 1G，频率TopN")]),_._v(" "),e("p",[_._v("10.两道"),e("a",{attrs:{href:""}},[_._v("算法题")])]),_._v(" "),e("p",[_._v("10.1")]),_._v(" "),e("p",[_._v("add(x)")]),_._v(" "),e("p",[_._v("delete(x)")]),_._v(" "),e("p",[_._v("random()")]),_._v(" "),e("p",[_._v("设计一个数据结构满足三种操作时间复杂度O(1)")]),_._v(" "),e("p",[_._v("10.2 岛屿问题变形，八个方向")]),_._v(" "),e("p",[_._v("11.反问：您觉得我之后要加强哪方面学习")]),_._v(" "),e("p",[_._v("flink，kafka要深入学一下，jvm多线程要补一补，之后会有三面")]),_._v(" "),e("p",[_._v("过了一个多小时，接到电话，直接hr面了")]),_._v(" "),e("h2",{attrs:{id:"hr面-20min-5-25"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#hr面-20min-5-25"}},[_._v("#")]),_._v(" hr面，20min，5.25")]),_._v(" "),e("p",[_._v("大概就是个人优缺点，校园生活之类的，聊天")]),_._v(" "),e("p",[_._v("最后反问是不是hr面通过就录取了。没问题的话这周就发offer")]),_._v(" "),e("p",[_._v("俩小时之后就发offer了，太效率了，赞！")])])}),[],!1,null,null,null);v.default=r.exports}}]);