作者：Nnnnnnnniii
链接：https://www.nowcoder.com/discuss/664535?source_id=discuss_experience_nctrack&channel=-1
来源：牛客网

# 字节大数据研发实习一面二面hr面（已oc） 

 5.16投的简历，5.18被捞，约5.19一面 

 因为面试的时候比较放松，问的知识点也很多，所以尽量回忆 

##  一面，1h15min，5.19 

 感觉面试官特别好，上来刚聊两句我就十分放松了，然后就开始放飞自我hhhh 

 1.先来个自我介绍吧 

 3.kafka掌握怎么样，flink有没有接触过呢 

 4.先来个mr过程吧

> MapReduce的工作流程大致可以分为5步：
>
> 1. 分片、格式化数据
>
>    分片操作：将源文件划分为大小相等的小数据块，即数据分片split。
>
>    格式化操作：将划分好的分片（split）格式化为键值对<key,value>形式的数据，其中，key代表偏移量，value代表每一行内容。
>
> 2. 执行MapTask
>
>    **写入内存缓冲区**：每个Map任务都有一个内存缓冲区，输入的分片（split）数据经过Map任务处理后的中间结果写入内存缓冲区
>
>    **写入磁盘**：如果写入的数据达到内存缓冲的阈值，会启动一个线程将内存中的溢出数据写入磁盘，同时不影响Map中间结果继续写入缓冲区。
>
>    **对key进行排序**：在溢写过程中，MapReduce框架会对key进行排序。**合并溢写文件**：如果中间结果比较大，会形成多个溢写文件，最后的缓冲区数据也会全部溢写入磁盘形成一个溢写文件，如果是多个溢写文件，则最后合并所有的溢写文件为一个文件。输出形式为<key,value>
>
> 3. 执行Shuffle过程
>
>    将MapTask输出的处理结果数据分发给ReduceTask，并在分发的过程中，对数据按照key进行分区和排序，输出形式为<key,{value,list}>
>
> 4. 执行ReduceTask
>
>    输入ReduceTask的数据流是<key,{value list}>形式，用户可以自定义reduce()方法进行逻辑处理，最终以<key,value>的形式输出
>
> 5. 写入文件
>
>    MapReduce框架自动将ReduceTask生成的<key,value>传入OutputFormat的write方法，实现文件写入。



 5.每个小文件为什么要进行[排序]()，最后合成的大文件为什么进行[排序]() 



 6.一个wordcount案例，具体各个流程，map怎么做，reduce怎么做，很细 

 7.spark掌握怎么样，我说了解，然后就没问了 

 8.数仓呢，数据仓库的分层能说一下吗 

 9.数仓知识还了解什么

 10.你刚刚说雪花模型把维度表规范化了，那说一下你了解的范式吧 

 11.做题吧，两道sql，两道[算法]()，写出来 

  11.1 

  订单表 orders：订单 ID (order_id)、[销售]() (employee_id)、成交价格 (price) 

  [销售]()表 employees：[销售]() ID (employee_id)、[销售]()姓名 (employee_name)、所在区域 (region) 求各个[销售]()的总[销售]()额，要求有[销售]() ID、姓名、所在区域 

  11.2 

  订单表 orders：订单 ID (order_id)、[销售]() (employee_id)、成交价格 (price) 

  [销售]()表 employees：[销售]() ID (employee_id)、[销售]()姓名 (employee_name)、所在区域 (region) 求各个区域[销售]()额最高的[销售]()对应的[销售]() ID、姓名、所在区域、[销售]()额 

 11.3 

 给定一个升序整数数列 L（L 中没有重复元素）和一个整数 n，判定 n 是否在 L 中 

 11.4 

 给定一个集合，求这个[集合的所有子集]()组成的集合。可用序列来表示集合。 

 12.反问：您觉得我之后需要加强哪方面的学习 

 总结：面试的很舒服，聊着聊着状态就特别好，题都a了 

 一面结束，第二天早上就接到电话进行二面，约5.24 

##  二面，1h，5.24 

 二面面试官也很好，都有回应 

 1.自我介绍 

 2.实习时长 

 2.说一下mysql的索引吧 

 3.B树和B+树的区别，问的很细 

 4.你是考研还是保研，顺便说了下我简历的问题 

 5.spark掌握如何？问的很细，具体忘记了，完全没套路，很发散 

 6.jvm掌握如何？ 

 7.多线程呢？ 

  8.kafka呢，partition为什么采用磁盘顺序写？ 

 9.500G 的文件，机器 1core 1G，频率TopN 

 10.两道[算法题]() 

 10.1 

 add(x) 

 delete(x) 

 random() 

 设计一个数据结构满足三种操作时间复杂度O(1) 

 10.2 岛屿问题变形，八个方向 

 11.反问：您觉得我之后要加强哪方面学习 

 flink，kafka要深入学一下，jvm多线程要补一补，之后会有三面 

 过了一个多小时，接到电话，直接hr面了 

##  hr面，20min，5.25 

 大概就是个人优缺点，校园生活之类的，聊天 

 最后反问是不是hr面通过就录取了。没问题的话这周就发offer 

 俩小时之后就发offer了，太效率了，赞！